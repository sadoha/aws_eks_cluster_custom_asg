#
# EKS Worker Nodes Resources
#  * EKS Node Group to launch worker nodes
#

locals {
  eks_nodes_userdata = <<USERDATA
#!/bin/bash
set -o xtrace
/etc/eks/bootstrap.sh --apiserver-endpoint '${aws_eks_cluster.cluster.endpoint}' --b64-cluster-ca '${aws_eks_cluster.cluster.certificate_authority.0.data}' '${aws_eks_cluster.cluster.name}' --kubelet-extra-args '${var.kublet_extra_args}'
USERDATA
}

resource "aws_launch_configuration" "eks" {
  name_prefix                 	= "eks-${var.projectname}-${var.environment}"
  associate_public_ip_address 	= false
  iam_instance_profile        	= aws_iam_instance_profile.nodes.name
  image_id                    	= data.aws_ami.eks_worker_ami.id
  instance_type               	= var.instance_types
  security_groups  		= [aws_security_group.nodes.id]
  user_data_base64 		= base64encode(local.eks_nodes_userdata)
  key_name			= var.key_pair

  root_block_device {
    delete_on_termination 	= true
    encrypted             	= true
    iops                  	= var.iops
    volume_size           	= var.volume_size
    volume_type           	= var.volume_type
  }

  lifecycle {
    create_before_destroy 	= true
  }
}


resource "aws_autoscaling_group" "eks" {
  launch_configuration 		= aws_launch_configuration.eks.id
  force_delete          	= true
  health_check_grace_period     = 30
  health_check_type             = "EC2"
  desired_capacity     		= var.countindex
  min_size             		= var.countindex 
  max_size             		= var.countindex +2
  vpc_zone_identifier 		= var.subnet_private_id

  lifecycle {
    create_before_destroy               = true
  }

  tag {
    key                 	= "Name"
    value               	= "eks-${var.projectname}-${var.environment}"
    propagate_at_launch 	= true
  }

  tag {
    key                 	= "kubernetes.io/cluster/${aws_eks_cluster.cluster.name}"
    value               	= "owned"
    propagate_at_launch 	= true
  }
}

